---
title: "安装指南"
description: "MemMachine 本地化部署起点"
icon: "bookmark"
---

## MemMachine 安装指南

本指南将带你完成 MemMachine 的安装流程。我们会先介绍所需的前置条件，然后提供两种不同的安装方式。

<Steps>
<Step title="准备前置条件">

在安装 MemMachine 之前，需要先配置一些基础环境。请务必记录下过程中创建的密码或密钥，后续步骤会用到。

### A. 核心软件

- **Python 3.12+**：MemMachine 需要 Python 3.12 或以上版本。
- **PostgreSQL**：需要本地 PostgreSQL 实例并启用 `pgvector` 扩展。可参考官方 [PostgreSQL 下载页面](https://www.postgresql.org/download/) 获取安装说明。安装完成后，请创建一个数据库，并为其配置拥有完整权限的用户。
- **Neo4j**：需要准备 Neo4j 数据库。安装步骤可查阅官方 [Neo4j 文档](https://neo4j.com/docs/)。安装完成后，启动 Neo4j 服务器，并为默认用户 `neo4j` 设置密码。

### B. 账户与密钥

- **OpenAI API Key**：使用 MemMachine 需要 OpenAI 账户。可在 [OpenAI 平台](https://platform.openai.com/) 注册，并生成 **API Key** 以便稍后使用。

<Note>MemMachine 本身可以免费安装，但请注意，运行过程中会消耗你 OpenAI 账户中的 tokens。</Note>

</Step>
<Step title="选择安装方式">

你可以通过 Python 包管理器安装 MemMachine，或从 GitHub 仓库克隆源码。
<AccordionGroup>
<Accordion title="方式一：使用 Pip 安装">

适合希望在现有 Python 环境中直接集成 MemMachine 的用户，推荐使用此方法。

若尚未创建 Python 环境，可使用 `venv` 快速搭建：
```sh
python -m venv memmachine-env
source memmachine-env/bin/activate  # On Windows use `source memmachine-env/Scripts/activate`
```

A. 在终端中执行以下命令：

 - 如果你在纯 CPU 环境中运行 MemMachine，请使用：
```sh
   pip install memmachine
```
 - 如果你拥有 NVIDIA GPU 并希望利用 GPU 加速，请使用：
```sh
pip install memmachine[gpu]
```
B. 随后，通过以下命令安装 NLTK 相关依赖：
```sh
memmachine-nltk-setup
```
</Accordion>
<Accordion title="方式二：从 GitHub 源码安装">

适合希望参与项目贡献或直接使用最新源码的用户。

首先，克隆仓库并进入项目目录：

```sh
git clone https://github.com/MemMachine/MemMachine.git
cd MemMachine
```

然后，确保已配置好 Python 环境，可使用 `venv`、`conda` 等任意环境管理工具。

接下来，使用 `uv` 工具安装所有依赖。如果尚未安装 `uv`，请先执行以下命令：

```sh
# If you don't have uv installed, run this command:
curl -LsSf https://astral.sh/uv/install.sh | sh

# 安装项目依赖：
uv pip install .
```
<Note>若希望启用 NVIDIA GPU，请改用 `uv pip install ".[gpu]"` 来安装 GPU 相关依赖。</Note>
</Accordion>
</AccordionGroup>
</Step>
<Step title="创建配置文件 `cfg.yml`">

MemMachine 依赖单个配置文件 `cfg.yml` 来提供登录信息与运行选项。

请在准备运行 MemMachine 的目录中创建 `cfg.yml`，用于配置模型、存储等各项参数。

GitHub 仓库的 `sample_configs` 目录提供了两份示例：一份适用于纯 CPU 部署，另一份适用于启用 GPU 的环境。请选择与你环境匹配的版本。

<AccordionGroup>
<Accordion title="仅 CPU 环境">
可以使用以下 curl 命令，从 GitHub 仓库下载模板：
```sh
curl -o cfg.yml https://raw.githubusercontent.com/MemMachine/MemMachine/refs/heads/main/sample_configs/episodic_memory_config.cpu.sample
```
下面展示了纯 CPU 环境下 `cfg.yml` 的示例：

```sh expandable lines
logging:
  path: /tmp/memory_log
  level: info #| debug | error

long_term_memory:
  derivative_deriver: sentence
  metadata_prefix: "[$timestamp] $producer_id: "
  embedder: my_embedder_id
  reranker: my_reranker_id
  vector_graph_store: my_storage_id

SessionDB:
  uri: sqlitetest.db

Model:
  testmodel:
    model_vendor: openai
    model_name: "gpt-4o-mini"
    api_key: <YOUR_API_KEY>
    
storage:
  my_storage_id:
    vendor_name: neo4j
    host: localhost
    port: 7687
    user: neo4j
    password: <YOUR_PASSWORD_HERE>

  profile_storage:
    vendor_name: postgres
    host: localhost
    port: 5432
    user: postgres
    db_name: postgres
    password: <YOUR_PASSWORD_HERE>

profile_memory:
  llm_model: testmodel
  embedding_model: my_embedder_id
  database: profile_storage
  prompt: profile_prompt

sessionMemory:
  model_name: testmodel
  message_capacity: 500
  max_message_length: 16000
  max_token_num: 8000

embedder:
  my_embedder_id:
    model_vendor: openai
    model_name: "text-embedding-3-small"
    api_key: <YOUR_API_KEY>

reranker:
  my_reranker_id:
    type: "rrf-hybrid"
    reranker_ids:
      - id_ranker_id
      - bm_ranker_id
  id_ranker_id:
    type: "identity"
  bm_ranker_id:
    type: "bm25"

prompt:
  profile: profile_prompt
```
<Tip>请将示例中的占位符替换为你自己的信息，例如 OpenAI API Key 与 Neo4j 密码。</Tip>
</Accordion>
<Accordion title="启用 GPU 的环境">
可以使用以下 curl 命令，从 GitHub 仓库下载模板：
```sh
curl -o cfg.yml https://raw.githubusercontent.com/MemMachine/MemMachine/refs/heads/main/sample_configs/episodic_memory_config.gpu.sample
```
下面展示了支持 GPU 的 `cfg.yml` 示例：

```sh expandable lines
logging:
  path: /tmp/memory_log
  level: info #| debug | error

long_term_memory:
  derivative_deriver: sentence
  metadata_prefix: "[$timestamp] $producer_id: "
  embedder: my_embedder_id
  reranker: my_reranker_id
  vector_graph_store: my_storage_id

profile_memory:
  llm_model: testmodel
  embedding_model: my_embedder_id
  database: profile_storage
  prompt: profile_prompt


SessionDB:
  uri: sqlitetest.db

Model:
  testmodel:
    model_vendor: openai
    model_name: "gpt-4o-mini"
    api_key: <YOUR_API_KEY>
    
storage:
  my_storage_id:
    vendor_name: neo4j
    host: localhost
    port: 7687
    user: neo4j
    password: <YOUR_PASSWORD_HERE>

  profile_storage:
    vendor_name: postgres
    host: localhost
    port: 5432
    user: postgres
    db_name: postgres
    password: <YOUR_PASSWORD_HERE>

sessionMemory:
  model_name: testmodel
  message_capacity: 500
  max_message_length: 16000
  max_token_num: 8000

embedder:
  my_embedder_id:
    model_vendor: openai
    model_name: "text-embedding-3-small"
    api_key: <YOUR_API_KEY>

reranker:
  my_reranker_id:
    type: "rrf-hybrid"
    reranker_ids:
      - id_ranker_id
      - bm_ranker_id
      - ce_ranker_id
  id_ranker_id:
    type: "identity"
  bm_ranker_id:
    type: "bm25"
  ce_ranker_id:
    type: "cross-encoder"
    model_name: "cross-encoder/qnli-electra-base"

prompt:
  profile: profile_prompt
```
<Tip>同样别忘了替换其中的占位符，使之符合你的实际配置。</Tip>
</Accordion>
</AccordionGroup>
<Tip>
你也可以使用其他文件名，并通过 `MEMORY_CONFIG` 环境变量告知 MemMachine，例如：

```sh
export MEMORY_CONFIG="/home/steve/wibble.cfg" # 指定配置文件
memmachine # 启动 memmachine
```

```sh
MEMORY_CONFIG="/home/steve/wibble.cfg" memmachine # 设置变量并立即启动
```
</Tip>
</Step>
<Step title="启动 MemMachine">

一切准备就绪！在安装 MemMachine 的目录中运行以下命令。

首先，需要同步画像数据库的 schema。该命令只需执行 **一次**，必须在第一次启动服务之前完成。

```
memmachine-sync-profile-schema
```

接下来启动 MemMachine 服务。如果之前已经同步过 schema，可直接执行以下命令：

```
memmachine-server
```

现在 MemMachine 服务就已经运行起来了。

<Note>若数据库通过 Docker 运行，请确认相关容器已启动且可访问，再启动 MemMachine。</Note>
</Step>
</Steps>
